{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:43:22.506733800Z",
     "start_time": "2023-08-22T18:43:14.975235400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all files df ...\n",
      "Reading all files np ...\n",
      "Training [3, 4, 5], Val 1, Test 2\n"
     ]
    }
   ],
   "source": [
    "from context import Context\n",
    "from data import Data\n",
    "from baselines import cross_val\n",
    "from util import Metric\n",
    "\n",
    "Context.data_dir = \"/home/foumani/data/solar_flare_prediction\"\n",
    "Context.files_df_filename = \"all_files.csv\"\n",
    "Context.files_np_filename = \"full_data_X_1_25.npy\"\n",
    "context = Context(train_n=[1500, 800], val_part=1, test_part=2)\n",
    "data = Data()\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data.numpy_datasets(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sktime.classification.deep_learning import LSTMFCNClassifier\n",
    "\n",
    "def baseline_lstm(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    clf = LSTMFCNClassifier(n_epochs=200, verbose=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    return Metric(y_true=y_val, y_pred=y_val_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:45:07.148520Z",
     "start_time": "2023-08-22T18:45:07.123888100Z"
    }
   },
   "id": "30fdadff4769c582"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [3, 4, 5], Val 1, Test 2\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 60, 128)              24704     ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 60, 128)              512       ['conv1d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 60, 128)              0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 60, 256)              164096    ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 60, 256)              1024      ['conv1d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 60, 256)              0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 60, 128)              98432     ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " permute_4 (Permute)         (None, 24, 60)               0         ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 60, 128)              512       ['conv1d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, 8)                    2208      ['permute_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 60, 128)              0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 8)                    0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (None, 128)                  0         ['activation_14[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 136)                  0         ['dropout_4[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 2)                    274       ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 12ms/step - loss: 0.2794 - accuracy: 0.8831\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2084 - accuracy: 0.9175\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1880 - accuracy: 0.9224\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1735 - accuracy: 0.9279\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1611 - accuracy: 0.9393\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1497 - accuracy: 0.9398\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1420 - accuracy: 0.9418\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.9373\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1324 - accuracy: 0.9498\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1345 - accuracy: 0.9448\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1179 - accuracy: 0.9547\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1148 - accuracy: 0.9572\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1132 - accuracy: 0.9468\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9642\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0930 - accuracy: 0.9632\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9637\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9647\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0953 - accuracy: 0.9652\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1065 - accuracy: 0.9587\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0919 - accuracy: 0.9647\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 0.9712\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9722\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0737 - accuracy: 0.9761\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0723 - accuracy: 0.9731\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0834 - accuracy: 0.9667\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0624 - accuracy: 0.9771\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9806\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0588 - accuracy: 0.9761\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0621 - accuracy: 0.9771\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0769 - accuracy: 0.9692\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0683 - accuracy: 0.9727\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9766\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0490 - accuracy: 0.9861\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9801\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.9851\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0308 - accuracy: 0.9901\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9861\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9896\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9866\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9841\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0366 - accuracy: 0.9896\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9876\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9881\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9866\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9925\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9861\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0461 - accuracy: 0.9806\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0670 - accuracy: 0.9766\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9856\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0345 - accuracy: 0.9861\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9896\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9935\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9896\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9920\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0392 - accuracy: 0.9861\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9851\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9906\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9881\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9915\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9960\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0330 - accuracy: 0.9915\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9891\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0499 - accuracy: 0.9821\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9950\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9975\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9915\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9915\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0499 - accuracy: 0.9826\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.9811\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9940\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9960\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9955\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9945\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9945\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9915\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9940\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9955\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9950\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9970\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9910\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9896\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9891\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9940\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9965\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9965\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9970\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9960\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9910\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9906\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9920\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9930\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9930\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9925\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9965\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9940\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9925\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9970\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9965\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9945\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9950\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9940\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9985\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.9970\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9955\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9920\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9901\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9940\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9950\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9940\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9866\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9920\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9955\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9925\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9940\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9925\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9910\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9896\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9930\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9960\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9955\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9965\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9965\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9975\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.9975\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9965\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9960\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9970\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9955\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9940\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9925\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9975\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9970\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9950\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9940\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9950\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9970\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9980\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9950\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9960\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9985\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9940\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9915\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.9896\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9915\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9940\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9955\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9950\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9965\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9965\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9935\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9925\n",
      "541/541 [==============================] - 2s 4ms/step\n",
      "val_part: 1, test_part: 2, Metric(tp: 634, fp: 3457, tn: 64552, fn: 546, tss: 48.64566279986371)\n",
      "Training [2, 4, 5], Val 1, Test 3\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 60, 128)              24704     ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 60, 128)              512       ['conv1d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 60, 128)              0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 60, 256)              164096    ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 60, 256)              1024      ['conv1d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 60, 256)              0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 60, 128)              98432     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " permute_5 (Permute)         (None, 24, 60)               0         ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 60, 128)              512       ['conv1d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 8)                    2208      ['permute_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 60, 128)              0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 8)                    0         ['lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5  (None, 128)                  0         ['activation_17[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 136)                  0         ['dropout_5[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 2)                    274       ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 12ms/step - loss: 0.2920 - accuracy: 0.8845\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1935 - accuracy: 0.9218\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.9331\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1518 - accuracy: 0.9430\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9449\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1352 - accuracy: 0.9440\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1245 - accuracy: 0.9503\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1148 - accuracy: 0.9558\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1056 - accuracy: 0.9641\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9607\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1136 - accuracy: 0.9572\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1015 - accuracy: 0.9582\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0819 - accuracy: 0.9666\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0718 - accuracy: 0.9774\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9730\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9764\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0595 - accuracy: 0.9764\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9774\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9789\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0590 - accuracy: 0.9769\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9735\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.9744\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0585 - accuracy: 0.9813\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0531 - accuracy: 0.9823\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0414 - accuracy: 0.9887\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9789\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0495 - accuracy: 0.9808\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9862\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0373 - accuracy: 0.9857\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 0.9774\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9897\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9897\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9921\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9887\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9872\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9867\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0334 - accuracy: 0.9902\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9892\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0376 - accuracy: 0.9867\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9862\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9961\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9921\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9941\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9956\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9946\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9921\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9897\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9897\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9926\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9931\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9946\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9892\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9936\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9966\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9941\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9931\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9892\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9887\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9951\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9946\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9941\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9941\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9985\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0093 - accuracy: 0.9980\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9951\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9897\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0568 - accuracy: 0.9828\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9887\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9892\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9956\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9951\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9941\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9951\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9961\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9926\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9985\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9961\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9912\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0321 - accuracy: 0.9867\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9912\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9916\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9951\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9936\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9980\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9980\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9980\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9980\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9961\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9980\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9956\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9941\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9921\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9926\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9941\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9921\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9951\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9956\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.9980\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9971\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9980\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.6763e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.8836e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8.7102e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.4455e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.1057e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.9990\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0403 - accuracy: 0.9877\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9892\n",
      "541/541 [==============================] - 2s 4ms/step\n",
      "val_part: 1, test_part: 3, Metric(tp: 690, fp: 3677, tn: 64332, fn: 490, tss: 53.06793891436601)\n",
      "Training [2, 3, 5], Val 1, Test 4\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 60, 128)              24704     ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 60, 128)              512       ['conv1d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 60, 128)              0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 60, 256)              164096    ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 60, 256)              1024      ['conv1d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 60, 256)              0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 60, 128)              98432     ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " permute_6 (Permute)         (None, 24, 60)               0         ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 60, 128)              512       ['conv1d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               (None, 8)                    2208      ['permute_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 60, 128)              0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 8)                    0         ['lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6  (None, 128)                  0         ['activation_20[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 136)                  0         ['dropout_6[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 2)                    274       ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 0.2819 - accuracy: 0.8801\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1917 - accuracy: 0.9205\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1605 - accuracy: 0.9353\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1577 - accuracy: 0.9358\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1529 - accuracy: 0.9348\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1357 - accuracy: 0.9472\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1261 - accuracy: 0.9497\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1255 - accuracy: 0.9447\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1246 - accuracy: 0.9472\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1142 - accuracy: 0.9541\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 0.9546\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0918 - accuracy: 0.9664\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9645\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0998 - accuracy: 0.9566\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0946 - accuracy: 0.9605\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9635\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 0.9724\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0763 - accuracy: 0.9689\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9724\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9620\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0759 - accuracy: 0.9674\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0691 - accuracy: 0.9733\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0626 - accuracy: 0.9768\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0617 - accuracy: 0.9803\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0519 - accuracy: 0.9817\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9808\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0527 - accuracy: 0.9832\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0503 - accuracy: 0.9808\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9798\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0715 - accuracy: 0.9684\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9778\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0544 - accuracy: 0.9768\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9847\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0494 - accuracy: 0.9798\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.9773\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0468 - accuracy: 0.9808\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0655 - accuracy: 0.9758\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0438 - accuracy: 0.9842\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0373 - accuracy: 0.9862\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9857\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9872\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9906\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9872\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9911\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9882\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9891\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9862\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9941\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9901\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9936\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9946\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9951\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9911\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9921\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9961\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9877\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9891\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9921\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.9783\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0485 - accuracy: 0.9852\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9891\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9921\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9886\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9916\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9896\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9921\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9926\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9946\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9956\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9936\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9911\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9941\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9946\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9975\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9926\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9946\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9946\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9970\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9975\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9941\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9872\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9901\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9916\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9916\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9906\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9941\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9946\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9936\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9946\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9995\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9946\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9946\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9941\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9951\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9946\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9961\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 0.9990\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9980\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9951\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9886\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.9921\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9926\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9951\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9946\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9956\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9931\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9965\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9951\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9936\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9882\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9896\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9931\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9961\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9931\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9985\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9975\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9965\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9951\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9975\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9961\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9951\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9941\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9970\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9970\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9951\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 0.9926\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9921\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9926\n",
      "541/541 [==============================] - 2s 3ms/step\n",
      "val_part: 1, test_part: 4, Metric(tp: 937, fp: 5064, tn: 62945, fn: 243, tss: 71.96070634719085)\n",
      "Training [2, 3, 4], Val 1, Test 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 60, 128)              24704     ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 60, 128)              512       ['conv1d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 60, 128)              0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 60, 256)              164096    ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 60, 256)              1024      ['conv1d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 60, 256)              0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 60, 128)              98432     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " permute_7 (Permute)         (None, 24, 60)               0         ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 60, 128)              512       ['conv1d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, 8)                    2208      ['permute_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 60, 128)              0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 8)                    0         ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7  (None, 128)                  0         ['activation_23[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 136)                  0         ['dropout_7[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 2)                    274       ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 26ms/step - loss: 0.3181 - accuracy: 0.8686\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2264 - accuracy: 0.9043\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2019 - accuracy: 0.9159\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1857 - accuracy: 0.9230\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1741 - accuracy: 0.9320\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1681 - accuracy: 0.9320\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1641 - accuracy: 0.9345\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1555 - accuracy: 0.9411\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1491 - accuracy: 0.9361\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1469 - accuracy: 0.9406\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1340 - accuracy: 0.9461\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1377 - accuracy: 0.9446\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1277 - accuracy: 0.9466\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1230 - accuracy: 0.9537\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1129 - accuracy: 0.9587\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1158 - accuracy: 0.9572\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1051 - accuracy: 0.9557\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9582\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1032 - accuracy: 0.9592\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1003 - accuracy: 0.9607\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0931 - accuracy: 0.9688\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9683\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0884 - accuracy: 0.9668\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0769 - accuracy: 0.9733\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9778\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.9688\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0841 - accuracy: 0.9698\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0737 - accuracy: 0.9738\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9794\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9773\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0736 - accuracy: 0.9763\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9783\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0584 - accuracy: 0.9763\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9794\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9778\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.9809\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9768\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9794\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9768\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0447 - accuracy: 0.9879\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.9814\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0540 - accuracy: 0.9783\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9753\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.9743\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0428 - accuracy: 0.9864\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9849\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9894\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9874\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9899\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9899\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.9879\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9899\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9844\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0412 - accuracy: 0.9824\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0404 - accuracy: 0.9844\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9849\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9889\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9889\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0384 - accuracy: 0.9874\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9899\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9914\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9904\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9924\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9914\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9919\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9829\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0595 - accuracy: 0.9799\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0455 - accuracy: 0.9849\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9899\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9914\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9940\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9960\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9930\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9955\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9914\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9924\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9854\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0506 - accuracy: 0.9824\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0388 - accuracy: 0.9849\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9914\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9924\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9950\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9955\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9975\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9940\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9930\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9945\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9940\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9955\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9980\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9919\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9919\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9924\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9919\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9889\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9960\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9945\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9924\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9930\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9930\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9924\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9909\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9930\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0353 - accuracy: 0.9864\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9869\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9950\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9955\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9919\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9950\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9965\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9945\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9970\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9975\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0111 - accuracy: 0.9960\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9965\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9930\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9940\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9909\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9930\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9945\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9970\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9945\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9909\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9904\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.9899\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9950\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9950\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9975\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9945\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9945\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9924\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9965\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9960\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9955\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9970\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9985\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9970\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9945\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9960\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9960\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9975\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9975\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9960\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9960\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 0.9940\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0299 - accuracy: 0.9914\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0329 - accuracy: 0.9869\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9859\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.9864\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9884\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9930\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9935\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9950\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9940\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "541/541 [==============================] - 2s 4ms/step\n",
      "val_part: 1, test_part: 5, Metric(tp: 766, fp: 3081, tn: 64928, fn: 414, tss: 60.38497148059416)\n",
      "Training [3, 4, 5], Val 2, Test 1\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 60, 128)              24704     ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 60, 128)              512       ['conv1d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 60, 128)              0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)          (None, 60, 256)              164096    ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 60, 256)              1024      ['conv1d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 60, 256)              0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)          (None, 60, 128)              98432     ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " permute_8 (Permute)         (None, 24, 60)               0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 60, 128)              512       ['conv1d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, 8)                    2208      ['permute_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 60, 128)              0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 8)                    0         ['lstm_8[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8  (None, 128)                  0         ['activation_26[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 136)                  0         ['dropout_8[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 2)                    274       ['concatenate_8[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 12ms/step - loss: 0.3298 - accuracy: 0.8732\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2216 - accuracy: 0.9060\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1838 - accuracy: 0.9204\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1643 - accuracy: 0.9279\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9289\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1684 - accuracy: 0.9314\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1654 - accuracy: 0.9354\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1444 - accuracy: 0.9433\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1304 - accuracy: 0.9498\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1264 - accuracy: 0.9498\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1195 - accuracy: 0.9543\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1408 - accuracy: 0.9428\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1199 - accuracy: 0.9508\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1150 - accuracy: 0.9592\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9652\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9637\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1053 - accuracy: 0.9572\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0949 - accuracy: 0.9637\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0914 - accuracy: 0.9692\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1136 - accuracy: 0.9607\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9722\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0691 - accuracy: 0.9771\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0645 - accuracy: 0.9771\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0721 - accuracy: 0.9736\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.9647\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9647\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0848 - accuracy: 0.9697\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9712\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9741\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0638 - accuracy: 0.9771\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9756\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0718 - accuracy: 0.9687\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0621 - accuracy: 0.9771\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 0.9786\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9731\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0593 - accuracy: 0.9781\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0679 - accuracy: 0.9756\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.9796\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0520 - accuracy: 0.9811\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9781\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 0.9861\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0462 - accuracy: 0.9841\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9886\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0414 - accuracy: 0.9856\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0328 - accuracy: 0.9881\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.9836\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0361 - accuracy: 0.9886\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0375 - accuracy: 0.9876\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9886\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9861\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9876\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.9881\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9920\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9920\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9915\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9915\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9891\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9955\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9950\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9906\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9866\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 0.9851\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0548 - accuracy: 0.9791\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 0.9831\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0370 - accuracy: 0.9915\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0273 - accuracy: 0.9915\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9930\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9930\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9915\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9945\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9920\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9906\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9920\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9940\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9930\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9945\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9940\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9965\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0403 - accuracy: 0.9846\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9906\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9945\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9955\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9955\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9945\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9901\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9866\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0290 - accuracy: 0.9886\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9896\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0517 - accuracy: 0.9836\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9861\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0315 - accuracy: 0.9876\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9891\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9915\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9960\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9950\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9970\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9985\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9960\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9950\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9915\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9920\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9945\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9960\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9930\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9955\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9965\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9910\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9866\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9960\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9965\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9940\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9930\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9960\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9960\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9960\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9935\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9960\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9945\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9950\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9965\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9970\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9950\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9955\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9970\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9925\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9846\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9901\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9960\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9960\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9950\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9955\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9965\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9970\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9930\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9915\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9950\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9960\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9960\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9980\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9930\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9930\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9930\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9965\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 0.9960\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9950\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9975\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9970\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9965\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9970\n",
      "622/622 [==============================] - 2s 3ms/step\n",
      "val_part: 2, test_part: 1, Metric(tp: 884, fp: 3915, tn: 74341, fn: 401, tss: 63.79096303303058)\n",
      "Training [1, 4, 5], Val 2, Test 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)          (None, 60, 128)              24704     ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 60, 128)              512       ['conv1d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 60, 128)              0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)          (None, 60, 256)              164096    ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 60, 256)              1024      ['conv1d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 60, 256)              0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)          (None, 60, 128)              98432     ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " permute_9 (Permute)         (None, 24, 60)               0         ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 60, 128)              512       ['conv1d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, 8)                    2208      ['permute_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 60, 128)              0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 8)                    0         ['lstm_9[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9  (None, 128)                  0         ['activation_29[0][0]']       \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 136)                  0         ['dropout_9[0][0]',           \n",
      " )                                                                   'global_average_pooling1d_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 2)                    274       ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 4s 30ms/step - loss: 0.2659 - accuracy: 0.8956\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.9300\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1537 - accuracy: 0.9345\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.9468\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1318 - accuracy: 0.9483\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.9438\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1219 - accuracy: 0.9581\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1260 - accuracy: 0.9458\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1196 - accuracy: 0.9527\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1051 - accuracy: 0.9640\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 0.9685\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0892 - accuracy: 0.9680\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0871 - accuracy: 0.9685\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0870 - accuracy: 0.9719\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0746 - accuracy: 0.9719\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0732 - accuracy: 0.9744\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0790 - accuracy: 0.9724\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9596\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0970 - accuracy: 0.9601\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0734 - accuracy: 0.9739\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0704 - accuracy: 0.9739\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9813\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.9793\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0681 - accuracy: 0.9719\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0600 - accuracy: 0.9793\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0566 - accuracy: 0.9778\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9788\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9818\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0526 - accuracy: 0.9803\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0520 - accuracy: 0.9818\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9842\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9867\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9867\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9842\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0382 - accuracy: 0.9877\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0466 - accuracy: 0.9818\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.9847\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0386 - accuracy: 0.9867\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9892\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9931\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9877\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9877\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9842\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9892\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9926\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9961\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9936\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9916\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9946\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9946\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9921\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9926\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9956\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9956\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9956\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9946\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9970\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9951\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9985\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9961\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9946\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9941\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9951\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9970\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9921\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9966\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9966\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9980\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9946\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9936\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9936\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9951\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9970\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9926\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9936\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0359 - accuracy: 0.9897\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9946\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9970\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9946\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9980\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9980\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 0.9970\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9961\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9956\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9970\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9931\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9951\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9951\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9951\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9970\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9980\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9956\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9966\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9946\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 0.9995\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9970\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9941\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9975\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9966\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9975\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9975\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9980\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9980\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.8003e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 0.9990\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9995\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9941\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9926\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9936\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9946\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9926\n",
      "622/622 [==============================] - 3s 4ms/step\n",
      "val_part: 2, test_part: 3, Metric(tp: 723, fp: 5645, tn: 72611, fn: 562, tss: 49.05108704385963)\n",
      "Training [1, 3, 5], Val 2, Test 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)          (None, 60, 128)              24704     ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 60, 128)              512       ['conv1d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 60, 128)              0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)          (None, 60, 256)              164096    ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 60, 256)              1024      ['conv1d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 60, 256)              0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)          (None, 60, 128)              98432     ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " permute_10 (Permute)        (None, 24, 60)               0         ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 60, 128)              512       ['conv1d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, 8)                    2208      ['permute_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 60, 128)              0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 8)                    0         ['lstm_10[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_32[0][0]']       \n",
      " 0 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 136)                  0         ['dropout_10[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_10[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 2)                    274       ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 25ms/step - loss: 0.3560 - accuracy: 0.8628\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9064\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1870 - accuracy: 0.9266\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1716 - accuracy: 0.9323\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9424\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1410 - accuracy: 0.9405\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.9395\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9357\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1327 - accuracy: 0.9463\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1202 - accuracy: 0.9559\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1052 - accuracy: 0.9607\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1242 - accuracy: 0.9520\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1168 - accuracy: 0.9535\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0996 - accuracy: 0.9602\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1048 - accuracy: 0.9616\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 0.9587\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0978 - accuracy: 0.9640\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0872 - accuracy: 0.9679\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9655\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0924 - accuracy: 0.9683\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0940 - accuracy: 0.9650\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0834 - accuracy: 0.9683\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0894 - accuracy: 0.9616\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0755 - accuracy: 0.9722\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.9789\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0611 - accuracy: 0.9784\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9726\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 0.9746\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0606 - accuracy: 0.9770\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0701 - accuracy: 0.9746\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0542 - accuracy: 0.9827\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.9808\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0629 - accuracy: 0.9760\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9770\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0636 - accuracy: 0.9760\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0510 - accuracy: 0.9832\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0521 - accuracy: 0.9813\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0569 - accuracy: 0.9813\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 0.9842\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9813\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9760\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9851\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0530 - accuracy: 0.9798\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9760\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0546 - accuracy: 0.9794\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9837\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0360 - accuracy: 0.9880\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0382 - accuracy: 0.9894\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.9890\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0355 - accuracy: 0.9875\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0485 - accuracy: 0.9808\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0403 - accuracy: 0.9856\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9928\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9933\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9933\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9942\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.9923\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0492 - accuracy: 0.9856\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9851\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0621 - accuracy: 0.9774\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9856\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.9846\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9885\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0347 - accuracy: 0.9894\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0468 - accuracy: 0.9832\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0575 - accuracy: 0.9726\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0364 - accuracy: 0.9861\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0400 - accuracy: 0.9856\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9923\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9957\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9966\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9971\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9933\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9933\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9904\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0341 - accuracy: 0.9880\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9904\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9899\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0311 - accuracy: 0.9880\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0350 - accuracy: 0.9875\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9890\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9899\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9914\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9918\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9933\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9899\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9784\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9899\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9942\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9942\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9962\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9942\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9966\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9952\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9952\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 0.9851\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9866\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9909\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0331 - accuracy: 0.9904\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9947\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9952\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9933\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9947\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9942\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9971\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9918\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9952\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9885\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 0.9870\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9899\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9890\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9942\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9947\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9928\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9856\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9890\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9947\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9866\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9914\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9971\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9938\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9942\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9947\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9976\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9942\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9962\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9957\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9957\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9962\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9933\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9899\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0421 - accuracy: 0.9851\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9890\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9923\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9938\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9962\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9981\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9947\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9947\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9962\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9928\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9957\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9957\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9914\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9914\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9947\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9947\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9995\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9981\n",
      "622/622 [==============================] - 3s 4ms/step\n",
      "val_part: 2, test_part: 4, Metric(tp: 850, fp: 4281, tn: 73975, fn: 435, tss: 60.677352868406764)\n",
      "Training [1, 3, 4], Val 2, Test 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)          (None, 60, 128)              24704     ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 60, 128)              512       ['conv1d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 60, 128)              0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)          (None, 60, 256)              164096    ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 60, 256)              1024      ['conv1d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 60, 256)              0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)          (None, 60, 128)              98432     ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " permute_11 (Permute)        (None, 24, 60)               0         ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 60, 128)              512       ['conv1d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, 8)                    2208      ['permute_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 60, 128)              0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 8)                    0         ['lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_35[0][0]']       \n",
      " 1 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 136)                  0         ['dropout_11[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_11[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 2)                    274       ['concatenate_11[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 30ms/step - loss: 0.2946 - accuracy: 0.8743\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2028 - accuracy: 0.9136\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1876 - accuracy: 0.9229\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1815 - accuracy: 0.9170\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1671 - accuracy: 0.9337\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1542 - accuracy: 0.9396\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1512 - accuracy: 0.9342\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1372 - accuracy: 0.9425\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1422 - accuracy: 0.9361\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1501 - accuracy: 0.9371\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1267 - accuracy: 0.9519\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1201 - accuracy: 0.9543\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1196 - accuracy: 0.9568\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.9622\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1002 - accuracy: 0.9592\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1068 - accuracy: 0.9583\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9632\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1127 - accuracy: 0.9524\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0934 - accuracy: 0.9651\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9705\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0741 - accuracy: 0.9759\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9641\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0663 - accuracy: 0.9759\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0724 - accuracy: 0.9730\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0592 - accuracy: 0.9799\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0593 - accuracy: 0.9799\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9754\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0808 - accuracy: 0.9720\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9686\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9745\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9794\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0499 - accuracy: 0.9833\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0422 - accuracy: 0.9867\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0522 - accuracy: 0.9828\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.9794\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9843\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0545 - accuracy: 0.9804\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 0.9710\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9799\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9848\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0436 - accuracy: 0.9808\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9745\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0492 - accuracy: 0.9813\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0485 - accuracy: 0.9808\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9774\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9799\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 0.9843\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9872\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9858\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9867\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0296 - accuracy: 0.9897\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9858\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 0.9902\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9907\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9926\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9917\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0300 - accuracy: 0.9892\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9926\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9907\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9862\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0428 - accuracy: 0.9843\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9867\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.9872\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9907\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9862\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9843\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0429 - accuracy: 0.9828\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9887\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9931\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9931\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9946\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9956\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9917\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9921\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9951\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0134 - accuracy: 0.9961\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9853\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.9848\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9917\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9936\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9956\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9936\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9907\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9946\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9946\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9926\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9961\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9936\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9936\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9921\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9951\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9926\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9946\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9941\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9926\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9921\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9926\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9941\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9946\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9926\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9941\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9872\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9843\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0455 - accuracy: 0.9833\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0443 - accuracy: 0.9853\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9921\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9921\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9951\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9971\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9956\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9921\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9951\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9946\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9956\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9941\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9946\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0324 - accuracy: 0.9887\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0238 - accuracy: 0.9907\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9931\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.9912\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9907\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9917\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9956\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9887\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9936\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9956\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9961\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9951\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9921\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9941\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9956\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9956\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9946\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9956\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9907\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9912\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9931\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 0.9936\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9975\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9956\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9961\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 0.9975\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9956\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9946\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9966\n",
      "622/622 [==============================] - 3s 4ms/step\n",
      "val_part: 2, test_part: 5, Metric(tp: 853, fp: 3337, tn: 74919, fn: 432, tss: 62.1171131841459)\n",
      "Training [2, 4, 5], Val 3, Test 1\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)          (None, 60, 128)              24704     ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 60, 128)              512       ['conv1d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 60, 128)              0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)          (None, 60, 256)              164096    ['activation_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 60, 256)              1024      ['conv1d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 60, 256)              0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)          (None, 60, 128)              98432     ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " permute_12 (Permute)        (None, 24, 60)               0         ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 60, 128)              512       ['conv1d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)              (None, 8)                    2208      ['permute_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 60, 128)              0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 8)                    0         ['lstm_12[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_38[0][0]']       \n",
      " 2 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 136)                  0         ['dropout_12[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_12[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 2)                    274       ['concatenate_12[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 0.2885 - accuracy: 0.8776\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1875 - accuracy: 0.9287\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1643 - accuracy: 0.9361\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1503 - accuracy: 0.9395\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1370 - accuracy: 0.9489\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1227 - accuracy: 0.9523\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 0.9484\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1146 - accuracy: 0.9602\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1055 - accuracy: 0.9597\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0985 - accuracy: 0.9671\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1012 - accuracy: 0.9602\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0962 - accuracy: 0.9646\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0807 - accuracy: 0.9690\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0713 - accuracy: 0.9749\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0821 - accuracy: 0.9690\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0977 - accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0794 - accuracy: 0.9705\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0580 - accuracy: 0.9833\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9843\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0469 - accuracy: 0.9848\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9784\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9798\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.9808\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0636 - accuracy: 0.9769\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0687 - accuracy: 0.9749\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0548 - accuracy: 0.9828\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0426 - accuracy: 0.9848\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9848\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9887\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9907\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0325 - accuracy: 0.9872\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9823\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0418 - accuracy: 0.9838\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9897\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9926\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9941\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9916\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9966\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9916\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9887\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9902\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0288 - accuracy: 0.9907\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0276 - accuracy: 0.9902\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9838\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 0.9828\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0405 - accuracy: 0.9853\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9902\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9941\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9985\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9975\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9916\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9867\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9921\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9951\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9936\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9966\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9971\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9951\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9926\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9956\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9902\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0330 - accuracy: 0.9887\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0504 - accuracy: 0.9833\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9857\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9921\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9946\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9951\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9956\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9985\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9951\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0122 - accuracy: 0.9951\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.9995\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9966\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9956\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9907\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9916\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9907\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9921\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 0.9995\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9995\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 0.9995\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9971\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9980\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9961\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9892\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9946\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0239 - accuracy: 0.9936\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9902\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9912\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9931\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9961\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9985\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9975\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.9975\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9995\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9980\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9985\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9985\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.9990\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9966\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9951\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9887\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9897\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9877\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9902\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9946\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9946\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9946\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9975\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9961\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "296/296 [==============================] - 1s 4ms/step\n",
      "val_part: 3, test_part: 1, Metric(tp: 805, fp: 2697, tn: 33838, fn: 472, tss: 55.65640868074819)\n",
      "Training [1, 4, 5], Val 3, Test 2\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)          (None, 60, 128)              24704     ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 60, 128)              512       ['conv1d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 60, 128)              0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)          (None, 60, 256)              164096    ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 60, 256)              1024      ['conv1d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 60, 256)              0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)          (None, 60, 128)              98432     ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " permute_13 (Permute)        (None, 24, 60)               0         ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 60, 128)              512       ['conv1d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)              (None, 8)                    2208      ['permute_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 60, 128)              0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 8)                    0         ['lstm_13[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_41[0][0]']       \n",
      " 3 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (None, 136)                  0         ['dropout_13[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_13[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 2)                    274       ['concatenate_13[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 4s 11ms/step - loss: 0.2892 - accuracy: 0.8754\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1816 - accuracy: 0.9350\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1608 - accuracy: 0.9394\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1495 - accuracy: 0.9478\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1340 - accuracy: 0.9493\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1462 - accuracy: 0.9443\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1191 - accuracy: 0.9537\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1008 - accuracy: 0.9611\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1068 - accuracy: 0.9616\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1308 - accuracy: 0.9567\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9562\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1051 - accuracy: 0.9635\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9665\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0834 - accuracy: 0.9714\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9704\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0713 - accuracy: 0.9739\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9818\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0681 - accuracy: 0.9739\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9739\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 0.9798\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9823\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9813\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9803\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9739\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0511 - accuracy: 0.9833\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0488 - accuracy: 0.9823\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0510 - accuracy: 0.9837\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9823\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0372 - accuracy: 0.9867\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0492 - accuracy: 0.9808\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9852\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9837\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9897\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9887\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.9892\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9931\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0318 - accuracy: 0.9892\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0341 - accuracy: 0.9857\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9887\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9892\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9833\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0410 - accuracy: 0.9862\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9887\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9901\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9911\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9892\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9911\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9951\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9975\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9970\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9916\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9941\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9970\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9882\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0399 - accuracy: 0.9862\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9872\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 0.9823\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0401 - accuracy: 0.9872\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9921\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9980\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9951\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9980\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9956\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9926\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9970\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9966\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9956\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9931\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9975\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9956\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9961\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9936\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9901\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9926\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9911\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.9887\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0329 - accuracy: 0.9892\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9946\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9916\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9916\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9975\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9995\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9980\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9985\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 0.9995\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9975\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9956\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9980\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9966\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9990\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.9975\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9970\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9961\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9951\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9951\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 0.9985\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9970\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.9990\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.6399e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9975\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9961\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0531 - accuracy: 0.9837\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 0.9887\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9911\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9946\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9921\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9975\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 0.9990\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9980\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.2439e-04 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.9957e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.9990\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9.5109e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.1948e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.4788e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9990\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0073 - accuracy: 0.9966\n",
      "296/296 [==============================] - 1s 4ms/step\n",
      "val_part: 3, test_part: 2, Metric(tp: 840, fp: 3250, tn: 33285, fn: 437, tss: 56.88359034829884)\n",
      "Training [1, 2, 5], Val 3, Test 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)          (None, 60, 128)              24704     ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 60, 128)              512       ['conv1d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 60, 128)              0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)          (None, 60, 256)              164096    ['activation_42[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 60, 256)              1024      ['conv1d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 60, 256)              0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)          (None, 60, 128)              98432     ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " permute_14 (Permute)        (None, 24, 60)               0         ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 60, 128)              512       ['conv1d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)              (None, 8)                    2208      ['permute_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 60, 128)              0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 8)                    0         ['lstm_14[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_44[0][0]']       \n",
      " 4 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 136)                  0         ['dropout_14[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_14[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 2)                    274       ['concatenate_14[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 27ms/step - loss: 0.3071 - accuracy: 0.8763\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2026 - accuracy: 0.9191\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1892 - accuracy: 0.9263\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1696 - accuracy: 0.9316\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1524 - accuracy: 0.9403\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1445 - accuracy: 0.9413\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1434 - accuracy: 0.9422\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1549 - accuracy: 0.9432\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1363 - accuracy: 0.9490\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1186 - accuracy: 0.9523\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1128 - accuracy: 0.9571\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9610\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9629\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0926 - accuracy: 0.9644\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9634\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0830 - accuracy: 0.9653\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0763 - accuracy: 0.9735\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9745\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 0.9764\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0757 - accuracy: 0.9716\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9649\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0851 - accuracy: 0.9706\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0648 - accuracy: 0.9774\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0771 - accuracy: 0.9726\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1169 - accuracy: 0.9528\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9663\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9803\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0479 - accuracy: 0.9856\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0544 - accuracy: 0.9774\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0556 - accuracy: 0.9817\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0710 - accuracy: 0.9745\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0560 - accuracy: 0.9798\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0547 - accuracy: 0.9822\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0642 - accuracy: 0.9783\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0470 - accuracy: 0.9865\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9870\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0418 - accuracy: 0.9836\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9913\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9827\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0567 - accuracy: 0.9822\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0536 - accuracy: 0.9798\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0493 - accuracy: 0.9836\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9750\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0492 - accuracy: 0.9822\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0552 - accuracy: 0.9831\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0384 - accuracy: 0.9880\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9783\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.9880\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9860\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9933\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9904\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9942\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9894\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0581 - accuracy: 0.9769\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0542 - accuracy: 0.9788\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9860\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9937\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0381 - accuracy: 0.9836\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9889\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9841\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9918\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9952\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9947\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9933\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9889\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9894\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0451 - accuracy: 0.9841\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9928\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9884\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9870\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0288 - accuracy: 0.9923\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9860\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9894\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9952\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9976\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9971\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9947\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0436 - accuracy: 0.9831\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0285 - accuracy: 0.9899\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9909\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9937\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0311 - accuracy: 0.9904\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9928\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9884\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9913\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9986\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9947\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.9884\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9933\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9986\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9928\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9957\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9952\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.9918\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9788\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9909\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9889\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9899\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0349 - accuracy: 0.9899\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9875\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9947\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0133 - accuracy: 0.9947\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9981\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9976\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.9976\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9952\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9904\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 0.9928\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9937\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9957\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9976\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9913\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9875\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9947\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9918\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9947\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9981\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0464 - accuracy: 0.9856\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9884\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9937\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 0.9957\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.9986\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9981\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9976\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9976\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9909\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9928\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9961\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9986\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9981\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9995\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9884\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0736 - accuracy: 0.9812\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9774\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9957\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9976\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9981\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9990\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9986\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9995\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "296/296 [==============================] - 1s 3ms/step\n",
      "val_part: 3, test_part: 4, Metric(tp: 827, fp: 2697, tn: 33838, fn: 450, tss: 57.37919646461664)\n",
      "Training [1, 2, 4], Val 3, Test 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)          (None, 60, 128)              24704     ['input_16[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 60, 128)              512       ['conv1d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 60, 128)              0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)          (None, 60, 256)              164096    ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 60, 256)              1024      ['conv1d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 60, 256)              0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)          (None, 60, 128)              98432     ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " permute_15 (Permute)        (None, 24, 60)               0         ['input_16[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 60, 128)              512       ['conv1d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)              (None, 8)                    2208      ['permute_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 60, 128)              0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 8)                    0         ['lstm_15[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_47[0][0]']       \n",
      " 5 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 136)                  0         ['dropout_15[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_15[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 2)                    274       ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 32ms/step - loss: 0.3498 - accuracy: 0.8581\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2103 - accuracy: 0.9198\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1688 - accuracy: 0.9335\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9359\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9335\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1399 - accuracy: 0.9423\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9486\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1236 - accuracy: 0.9452\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1333 - accuracy: 0.9496\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1235 - accuracy: 0.9521\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9525\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1125 - accuracy: 0.9589\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1101 - accuracy: 0.9604\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1065 - accuracy: 0.9574\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0998 - accuracy: 0.9604\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9687\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0911 - accuracy: 0.9628\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9658\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0952 - accuracy: 0.9658\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0711 - accuracy: 0.9706\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0661 - accuracy: 0.9746\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0662 - accuracy: 0.9785\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0775 - accuracy: 0.9662\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0646 - accuracy: 0.9795\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9824\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0743 - accuracy: 0.9721\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0643 - accuracy: 0.9775\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9799\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0515 - accuracy: 0.9824\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0550 - accuracy: 0.9785\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 0.9804\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0565 - accuracy: 0.9824\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9785\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0471 - accuracy: 0.9824\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.9829\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0713 - accuracy: 0.9721\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9731\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0705 - accuracy: 0.9731\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0505 - accuracy: 0.9819\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9848\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0454 - accuracy: 0.9834\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0504 - accuracy: 0.9790\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9883\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0315 - accuracy: 0.9917\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 0.9922\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9917\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9927\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0402 - accuracy: 0.9878\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9868\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0467 - accuracy: 0.9814\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0453 - accuracy: 0.9843\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9897\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9907\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9936\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9941\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9941\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9932\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9956\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9912\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0354 - accuracy: 0.9883\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9892\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9887\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9936\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9927\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9946\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9927\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9936\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9907\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9946\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9951\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9936\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9946\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9936\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9946\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9951\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9956\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9936\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9941\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9932\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9956\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9951\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9956\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9961\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9936\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9922\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9941\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9956\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9932\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9932\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9927\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9907\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9927\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9976\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9912\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9946\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9956\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9932\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9946\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9946\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9932\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9927\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9917\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9927\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9985\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9956\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9936\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9976\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9912\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9868\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9848\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9907\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9946\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0109 - accuracy: 0.9976\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9946\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9966\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.9961\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9956\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9961\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9946\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9980\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9995\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.9980\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.9980\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9980\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9976\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9980\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.9980\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9966\n",
      "296/296 [==============================] - 1s 4ms/step\n",
      "val_part: 3, test_part: 5, Metric(tp: 897, fp: 3272, tn: 33263, fn: 380, tss: 61.28696064821935)\n",
      "Training [2, 3, 5], Val 4, Test 1\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)          (None, 60, 128)              24704     ['input_17[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 60, 128)              512       ['conv1d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 60, 128)              0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)          (None, 60, 256)              164096    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 60, 256)              1024      ['conv1d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 60, 256)              0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)          (None, 60, 128)              98432     ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " permute_16 (Permute)        (None, 24, 60)               0         ['input_17[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 60, 128)              512       ['conv1d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)              (None, 8)                    2208      ['permute_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 60, 128)              0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 8)                    0         ['lstm_16[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_50[0][0]']       \n",
      " 6 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 136)                  0         ['dropout_16[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_16[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 2)                    274       ['concatenate_16[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 0.2645 - accuracy: 0.8894\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1831 - accuracy: 0.9240\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1731 - accuracy: 0.9284\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1531 - accuracy: 0.9393\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9383\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1314 - accuracy: 0.9442\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1324 - accuracy: 0.9452\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1158 - accuracy: 0.9561\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1081 - accuracy: 0.9620\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1175 - accuracy: 0.9546\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1154 - accuracy: 0.9506\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1017 - accuracy: 0.9576\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1111 - accuracy: 0.9571\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1026 - accuracy: 0.9551\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0928 - accuracy: 0.9610\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.9699\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0839 - accuracy: 0.9635\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0796 - accuracy: 0.9714\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0717 - accuracy: 0.9753\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0787 - accuracy: 0.9709\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0784 - accuracy: 0.9679\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0692 - accuracy: 0.9714\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9753\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0529 - accuracy: 0.9798\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0623 - accuracy: 0.9763\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9748\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9803\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9788\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.9778\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9852\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9817\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0523 - accuracy: 0.9798\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0638 - accuracy: 0.9768\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0572 - accuracy: 0.9778\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0501 - accuracy: 0.9793\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0508 - accuracy: 0.9812\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.9808\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9872\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0347 - accuracy: 0.9857\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.9921\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9916\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9911\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0248 - accuracy: 0.9921\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9916\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0327 - accuracy: 0.9877\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0426 - accuracy: 0.9857\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9847\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0495 - accuracy: 0.9803\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0459 - accuracy: 0.9822\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9817\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0330 - accuracy: 0.9872\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9921\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9946\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9916\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9862\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0444 - accuracy: 0.9837\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9827\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9931\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9921\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9921\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9961\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9956\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9946\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9946\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9901\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0290 - accuracy: 0.9916\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9911\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9936\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9916\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9921\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9921\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9911\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9946\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9931\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9936\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9946\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9975\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9970\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9965\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9970\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9970\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9975\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9995\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9965\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9926\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9926\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9931\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9926\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9965\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9926\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9931\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9896\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9916\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9936\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9936\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9980\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 0.9951\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9956\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9985\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9956\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9961\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9936\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9970\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9965\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9995\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9956\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9961\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9956\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9975\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9970\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9956\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.9936\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9926\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9936\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9931\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9941\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9931\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.9936\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9970\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9951\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9965\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0051 - accuracy: 0.9985\n",
      "341/341 [==============================] - 2s 4ms/step\n",
      "val_part: 4, test_part: 1, Metric(tp: 643, fp: 2560, tn: 40135, fn: 247, tss: 66.25117274211777)\n",
      "Training [1, 3, 5], Val 4, Test 2\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)          (None, 60, 128)              24704     ['input_18[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 60, 128)              512       ['conv1d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 60, 128)              0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)          (None, 60, 256)              164096    ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, 60, 256)              1024      ['conv1d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 60, 256)              0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)          (None, 60, 128)              98432     ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " permute_17 (Permute)        (None, 24, 60)               0         ['input_18[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, 60, 128)              512       ['conv1d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_17 (LSTM)              (None, 8)                    2208      ['permute_17[0][0]']          \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 60, 128)              0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 8)                    0         ['lstm_17[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_53[0][0]']       \n",
      " 7 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 136)                  0         ['dropout_17[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_17[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 2)                    274       ['concatenate_17[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 4s 12ms/step - loss: 0.3055 - accuracy: 0.8767\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1986 - accuracy: 0.9199\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1701 - accuracy: 0.9304\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1582 - accuracy: 0.9386\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1385 - accuracy: 0.9453\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1379 - accuracy: 0.9467\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1370 - accuracy: 0.9415\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9467\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1359 - accuracy: 0.9448\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1274 - accuracy: 0.9443\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1032 - accuracy: 0.9602\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1060 - accuracy: 0.9645\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1034 - accuracy: 0.9563\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1136 - accuracy: 0.9554\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0947 - accuracy: 0.9631\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.9674\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9530\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0948 - accuracy: 0.9626\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0797 - accuracy: 0.9712\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9750\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0739 - accuracy: 0.9702\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0949 - accuracy: 0.9640\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0797 - accuracy: 0.9726\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0758 - accuracy: 0.9712\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9755\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0620 - accuracy: 0.9832\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0521 - accuracy: 0.9842\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0526 - accuracy: 0.9808\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0910 - accuracy: 0.9659\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0674 - accuracy: 0.9741\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9741\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1013 - accuracy: 0.9621\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.9779\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0549 - accuracy: 0.9798\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9827\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0520 - accuracy: 0.9808\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9803\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0583 - accuracy: 0.9779\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0643 - accuracy: 0.9755\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9794\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9861\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 0.9822\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0457 - accuracy: 0.9832\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0542 - accuracy: 0.9832\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0386 - accuracy: 0.9866\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9914\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9899\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9818\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0365 - accuracy: 0.9856\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0376 - accuracy: 0.9856\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0363 - accuracy: 0.9875\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0612 - accuracy: 0.9798\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.9842\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0380 - accuracy: 0.9880\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9894\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9899\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0285 - accuracy: 0.9899\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9909\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0315 - accuracy: 0.9904\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0464 - accuracy: 0.9846\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9846\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9770\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0516 - accuracy: 0.9822\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0413 - accuracy: 0.9846\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9894\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 0.9890\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 0.9880\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 0.9890\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9904\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9933\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 0.9866\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9870\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9880\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9861\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9885\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9923\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9918\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9909\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9909\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9914\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0374 - accuracy: 0.9846\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0330 - accuracy: 0.9875\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0446 - accuracy: 0.9851\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0460 - accuracy: 0.9832\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9914\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9928\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9928\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9866\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9837\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9894\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9928\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9933\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9923\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9914\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9928\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9952\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9885\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9914\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9942\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9928\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9923\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9928\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9938\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9938\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9904\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9918\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0269 - accuracy: 0.9909\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9914\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0259 - accuracy: 0.9914\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0308 - accuracy: 0.9861\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0360 - accuracy: 0.9842\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0274 - accuracy: 0.9890\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9933\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9976\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9966\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9962\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9962\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9957\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9981\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9986\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9966\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9952\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9923\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9899\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9914\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0365 - accuracy: 0.9866\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9923\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9957\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9885\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9962\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9938\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9952\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.9957\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9966\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9971\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9957\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9928\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9918\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9923\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9870\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9899\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0351 - accuracy: 0.9890\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9947\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9923\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0222 - accuracy: 0.9904\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9928\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9933\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0120 - accuracy: 0.9976\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9971\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9981\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9976\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9933\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9909\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9904\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9885\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9942\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9942\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9923\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9957\n",
      "341/341 [==============================] - 1s 3ms/step\n",
      "val_part: 4, test_part: 2, Metric(tp: 548, fp: 2567, tn: 40128, fn: 342, tss: 55.560620076292366)\n",
      "Training [1, 2, 5], Val 4, Test 3\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)          (None, 60, 128)              24704     ['input_19[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (None, 60, 128)              512       ['conv1d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 60, 128)              0         ['batch_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)          (None, 60, 256)              164096    ['activation_54[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (None, 60, 256)              1024      ['conv1d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 60, 256)              0         ['batch_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)          (None, 60, 128)              98432     ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " permute_18 (Permute)        (None, 24, 60)               0         ['input_19[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (None, 60, 128)              512       ['conv1d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_18 (LSTM)              (None, 8)                    2208      ['permute_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, 60, 128)              0         ['batch_normalization_56[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (None, 8)                    0         ['lstm_18[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_56[0][0]']       \n",
      " 8 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenat  (None, 136)                  0         ['dropout_18[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_18[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 2)                    274       ['concatenate_18[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 11ms/step - loss: 0.2928 - accuracy: 0.8849\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2324 - accuracy: 0.9023\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1944 - accuracy: 0.9206\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1657 - accuracy: 0.9355\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1626 - accuracy: 0.9340\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1604 - accuracy: 0.9355\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1628 - accuracy: 0.9326\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1430 - accuracy: 0.9432\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1288 - accuracy: 0.9499\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1237 - accuracy: 0.9519\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.9562\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1023 - accuracy: 0.9624\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0966 - accuracy: 0.9624\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.9624\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1111 - accuracy: 0.9629\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9519\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1016 - accuracy: 0.9596\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0910 - accuracy: 0.9653\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0790 - accuracy: 0.9692\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0757 - accuracy: 0.9716\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.9769\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9740\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0648 - accuracy: 0.9783\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0915 - accuracy: 0.9624\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0848 - accuracy: 0.9658\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0965 - accuracy: 0.9663\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0811 - accuracy: 0.9692\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9779\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0595 - accuracy: 0.9759\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9788\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0482 - accuracy: 0.9827\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0457 - accuracy: 0.9870\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9817\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9774\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0794 - accuracy: 0.9663\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9779\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 0.9918\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9899\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0462 - accuracy: 0.9822\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.9783\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.9653\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0571 - accuracy: 0.9803\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0399 - accuracy: 0.9904\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0380 - accuracy: 0.9860\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0469 - accuracy: 0.9822\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9817\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.9894\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 0.9884\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9899\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0376 - accuracy: 0.9870\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 0.9807\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0432 - accuracy: 0.9836\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0483 - accuracy: 0.9822\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0414 - accuracy: 0.9851\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9880\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9856\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9798\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 0.9865\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9909\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9918\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9909\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0435 - accuracy: 0.9836\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0433 - accuracy: 0.9851\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9894\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9966\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9961\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9957\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9889\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9870\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.9754\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9827\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0334 - accuracy: 0.9904\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9952\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9928\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9947\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9942\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 0.9990\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9846\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0272 - accuracy: 0.9884\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9928\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0315 - accuracy: 0.9913\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9889\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9923\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9952\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9923\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9913\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9952\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9961\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9986\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9986\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9995\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9947\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9937\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9952\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.9851\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9865\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9913\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9841\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9928\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9836\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 0.9798\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9894\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9913\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9976\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9957\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9976\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9942\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0430 - accuracy: 0.9851\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.9894\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0379 - accuracy: 0.9846\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9904\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.9923\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9909\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9981\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9923\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9933\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9904\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9913\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9894\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9933\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9966\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9928\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9952\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0467 - accuracy: 0.9860\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9884\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9942\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9957\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9981\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9918\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9976\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9928\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9937\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9913\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 0.9981\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9995\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9899\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9913\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9884\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9957\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9923\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9986\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9986\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 0.9966\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9933\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 0.9986\n",
      "341/341 [==============================] - 1s 3ms/step\n",
      "val_part: 4, test_part: 3, Metric(tp: 586, fp: 2361, tn: 40334, fn: 304, tss: 60.31277509273381)\n",
      "Training [1, 2, 3], Val 4, Test 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)          (None, 60, 128)              24704     ['input_20[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (None, 60, 128)              512       ['conv1d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, 60, 128)              0         ['batch_normalization_57[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)          (None, 60, 256)              164096    ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (None, 60, 256)              1024      ['conv1d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, 60, 256)              0         ['batch_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)          (None, 60, 128)              98432     ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " permute_19 (Permute)        (None, 24, 60)               0         ['input_20[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (None, 60, 128)              512       ['conv1d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_19 (LSTM)              (None, 8)                    2208      ['permute_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, 60, 128)              0         ['batch_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 8)                    0         ['lstm_19[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['activation_59[0][0]']       \n",
      " 9 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenat  (None, 136)                  0         ['dropout_19[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 2)                    274       ['concatenate_19[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 11ms/step - loss: 0.2788 - accuracy: 0.8835\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2086 - accuracy: 0.9148\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1721 - accuracy: 0.9316\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1834 - accuracy: 0.9186\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1623 - accuracy: 0.9307\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1501 - accuracy: 0.9393\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1489 - accuracy: 0.9456\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.9571\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1282 - accuracy: 0.9485\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9586\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1393 - accuracy: 0.9442\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1286 - accuracy: 0.9504\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9596\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9490\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1127 - accuracy: 0.9552\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1059 - accuracy: 0.9610\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 0.9673\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1024 - accuracy: 0.9615\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0922 - accuracy: 0.9644\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0922 - accuracy: 0.9649\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0889 - accuracy: 0.9692\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1067 - accuracy: 0.9581\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0765 - accuracy: 0.9745\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.9822\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0666 - accuracy: 0.9788\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.9807\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.9779\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.9807\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 0.9735\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0994 - accuracy: 0.9649\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0879 - accuracy: 0.9658\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9735\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0665 - accuracy: 0.9774\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0651 - accuracy: 0.9769\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.9788\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0781 - accuracy: 0.9721\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9779\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9793\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9865\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9841\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0423 - accuracy: 0.9894\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 0.9875\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 0.9754\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0550 - accuracy: 0.9793\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0580 - accuracy: 0.9798\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0464 - accuracy: 0.9841\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0886 - accuracy: 0.9682\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9754\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9831\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9764\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9788\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9827\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9836\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9841\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9851\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9913\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9928\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9875\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.9817\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 0.9798\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9831\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9865\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9904\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9894\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9860\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9894\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9923\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9942\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9947\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9923\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9933\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9750\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 0.9822\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9812\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 0.9851\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9860\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.9909\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9923\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9933\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9942\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9880\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9928\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0314 - accuracy: 0.9899\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0877 - accuracy: 0.9706\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9783\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9899\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9933\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9933\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9880\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9870\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9918\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9904\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9947\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9957\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9909\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9923\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 0.9851\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9909\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9913\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9966\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9957\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0488 - accuracy: 0.9836\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.9875\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9928\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9865\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9923\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9952\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0458 - accuracy: 0.9889\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9904\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9933\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9870\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9889\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9923\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9957\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9894\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9904\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9913\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9942\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9928\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9928\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9952\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9952\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9952\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.9947\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9913\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9918\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0125 - accuracy: 0.9952\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9966\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9933\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9966\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9966\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 0.9952\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9957\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 0.9831\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0325 - accuracy: 0.9870\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9904\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9933\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 0.9841\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0361 - accuracy: 0.9884\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9889\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9928\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9952\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9961\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0585 - accuracy: 0.9822\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 0.9856\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9928\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9942\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9952\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9918\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9933\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9957\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9966\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.9966\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9976\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9913\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.9870\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9904\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9923\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9947\n",
      "341/341 [==============================] - 1s 3ms/step\n",
      "val_part: 4, test_part: 5, Metric(tp: 501, fp: 2574, tn: 40121, fn: 389, tss: 50.26332583743327)\n",
      "Training [2, 3, 4], Val 5, Test 1\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_60 (Conv1D)          (None, 60, 128)              24704     ['input_21[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (None, 60, 128)              512       ['conv1d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, 60, 128)              0         ['batch_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_61 (Conv1D)          (None, 60, 256)              164096    ['activation_60[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (None, 60, 256)              1024      ['conv1d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, 60, 256)              0         ['batch_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_62 (Conv1D)          (None, 60, 128)              98432     ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " permute_20 (Permute)        (None, 24, 60)               0         ['input_21[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (None, 60, 128)              512       ['conv1d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_20 (LSTM)              (None, 8)                    2208      ['permute_20[0][0]']          \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, 60, 128)              0         ['batch_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 8)                    0         ['lstm_20[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['activation_62[0][0]']       \n",
      " 0 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenat  (None, 136)                  0         ['dropout_20[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_20[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 2)                    274       ['concatenate_20[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 11ms/step - loss: 0.3144 - accuracy: 0.8771\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2343 - accuracy: 0.9079\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2011 - accuracy: 0.9164\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1867 - accuracy: 0.9199\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1929 - accuracy: 0.9225\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9250\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.9371\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.9366\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1503 - accuracy: 0.9411\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1479 - accuracy: 0.9391\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1378 - accuracy: 0.9481\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1362 - accuracy: 0.9461\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1265 - accuracy: 0.9507\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1290 - accuracy: 0.9517\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1173 - accuracy: 0.9512\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.9486\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9527\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9632\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0863 - accuracy: 0.9723\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1013 - accuracy: 0.9592\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.9552\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1208 - accuracy: 0.9542\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.9748\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9688\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9718\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9809\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0792 - accuracy: 0.9728\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.9718\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9708\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9733\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9698\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 0.9632\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0619 - accuracy: 0.9799\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0540 - accuracy: 0.9834\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 0.9804\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9809\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.9789\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 0.9819\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 0.9864\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 0.9844\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 0.9839\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9869\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0458 - accuracy: 0.9829\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9804\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9768\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9849\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.9799\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9854\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0513 - accuracy: 0.9804\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 0.9849\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0374 - accuracy: 0.9884\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9844\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9854\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9839\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9919\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9914\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9869\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9914\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9930\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9859\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9899\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 0.9879\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9854\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9884\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9904\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9904\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.9874\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9945\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9965\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9930\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9930\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9914\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0180 - accuracy: 0.9955\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9945\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0263 - accuracy: 0.9914\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9924\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9914\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9899\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9960\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9950\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0222 - accuracy: 0.9940\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 0.9924\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9960\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9935\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9945\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9955\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9970\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9919\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9919\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9909\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9930\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9965\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9960\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9955\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9970\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0348 - accuracy: 0.9859\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 0.9809\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 0.9804\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0444 - accuracy: 0.9834\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0246 - accuracy: 0.9909\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9904\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9919\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9960\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9975\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9960\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9945\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 0.9960\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9970\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 0.9965\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9970\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9940\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0076 - accuracy: 0.9990\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9960\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9980\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9990\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0108 - accuracy: 0.9975\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9960\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9899\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9909\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9814\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0405 - accuracy: 0.9859\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9909\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9914\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9965\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9940\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9940\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.9980\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9945\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 0.9894\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9849\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0565 - accuracy: 0.9783\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0346 - accuracy: 0.9884\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9924\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9950\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9955\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9990\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.9980\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9985\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9975\n",
      "520/520 [==============================] - 2s 4ms/step\n",
      "val_part: 5, test_part: 1, Metric(tp: 501, fp: 2060, tn: 63549, fn: 393, tss: 52.90045532098282)\n",
      "Training [1, 3, 4], Val 5, Test 2\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_63 (Conv1D)          (None, 60, 128)              24704     ['input_22[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (None, 60, 128)              512       ['conv1d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, 60, 128)              0         ['batch_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)          (None, 60, 256)              164096    ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, 60, 256)              1024      ['conv1d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, 60, 256)              0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)          (None, 60, 128)              98432     ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " permute_21 (Permute)        (None, 24, 60)               0         ['input_22[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, 60, 128)              512       ['conv1d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_21 (LSTM)              (None, 8)                    2208      ['permute_21[0][0]']          \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, 60, 128)              0         ['batch_normalization_65[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 8)                    0         ['lstm_21[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['activation_65[0][0]']       \n",
      " 1 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenat  (None, 136)                  0         ['dropout_21[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_21[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 2)                    274       ['concatenate_21[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 4s 12ms/step - loss: 0.3035 - accuracy: 0.8698\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2108 - accuracy: 0.9086\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9249\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1727 - accuracy: 0.9278\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9258\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9249\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1516 - accuracy: 0.9371\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1453 - accuracy: 0.9396\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1341 - accuracy: 0.9430\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1268 - accuracy: 0.9465\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1357 - accuracy: 0.9406\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1394 - accuracy: 0.9416\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1208 - accuracy: 0.9499\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1061 - accuracy: 0.9578\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0944 - accuracy: 0.9637\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.9705\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1052 - accuracy: 0.9617\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0971 - accuracy: 0.9637\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0776 - accuracy: 0.9730\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9637\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1045 - accuracy: 0.9543\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1064 - accuracy: 0.9548\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0829 - accuracy: 0.9671\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0790 - accuracy: 0.9740\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0844 - accuracy: 0.9691\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0946 - accuracy: 0.9637\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.9686\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0856 - accuracy: 0.9695\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0636 - accuracy: 0.9759\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0635 - accuracy: 0.9769\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9799\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0539 - accuracy: 0.9833\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0507 - accuracy: 0.9789\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.9745\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9745\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0571 - accuracy: 0.9789\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9804\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9853\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0505 - accuracy: 0.9804\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9862\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9902\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0382 - accuracy: 0.9877\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9872\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0350 - accuracy: 0.9877\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0372 - accuracy: 0.9882\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0315 - accuracy: 0.9882\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 0.9848\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.9867\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9877\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9862\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9892\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9862\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0483 - accuracy: 0.9853\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0436 - accuracy: 0.9843\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9877\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9902\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0420 - accuracy: 0.9872\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9897\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9897\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0376 - accuracy: 0.9877\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0372 - accuracy: 0.9892\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9921\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0348 - accuracy: 0.9897\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.9941\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9921\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9931\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9926\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9926\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9931\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9926\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9912\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9951\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9946\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0414 - accuracy: 0.9867\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0352 - accuracy: 0.9882\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9848\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9921\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9921\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9902\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9912\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0296 - accuracy: 0.9872\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9887\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9936\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.9956\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9971\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 0.9921\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9882\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0444 - accuracy: 0.9848\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9892\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.9917\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9941\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9902\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0223 - accuracy: 0.9917\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9912\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9956\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 0.9951\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9912\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9946\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9926\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9961\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9951\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9921\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9917\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9926\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9971\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9921\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0334 - accuracy: 0.9882\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9946\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9921\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9966\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9941\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9941\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9966\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9951\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0092 - accuracy: 0.9956\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9961\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9941\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9941\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0079 - accuracy: 0.9971\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.9980\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9975\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9975\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9980\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9971\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 0.9985\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.9975\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 0.9971\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9975\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9966\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9926\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0361 - accuracy: 0.9877\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0548 - accuracy: 0.9828\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 0.9838\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9823\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.9853\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9858\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9931\n",
      "520/520 [==============================] - 2s 3ms/step\n",
      "val_part: 5, test_part: 2, Metric(tp: 532, fp: 1982, tn: 63627, fn: 362, tss: 56.486902970663124)\n",
      "Training [1, 2, 4], Val 5, Test 3\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)          (None, 60, 128)              24704     ['input_23[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, 60, 128)              512       ['conv1d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, 60, 128)              0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)          (None, 60, 256)              164096    ['activation_66[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, 60, 256)              1024      ['conv1d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, 60, 256)              0         ['batch_normalization_67[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)          (None, 60, 128)              98432     ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " permute_22 (Permute)        (None, 24, 60)               0         ['input_23[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, 60, 128)              512       ['conv1d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)              (None, 8)                    2208      ['permute_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, 60, 128)              0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)        (None, 8)                    0         ['lstm_22[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['activation_68[0][0]']       \n",
      " 2 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenat  (None, 136)                  0         ['dropout_22[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_22[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 2)                    274       ['concatenate_22[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 13ms/step - loss: 0.2765 - accuracy: 0.8787\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2051 - accuracy: 0.9159\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1873 - accuracy: 0.9281\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1729 - accuracy: 0.9335\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1573 - accuracy: 0.9374\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9408\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1453 - accuracy: 0.9369\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1290 - accuracy: 0.9501\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1130 - accuracy: 0.9535\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1174 - accuracy: 0.9535\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1185 - accuracy: 0.9521\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1004 - accuracy: 0.9638\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9648\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0897 - accuracy: 0.9697\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0847 - accuracy: 0.9682\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0852 - accuracy: 0.9667\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0900 - accuracy: 0.9711\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0884 - accuracy: 0.9643\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0807 - accuracy: 0.9653\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0793 - accuracy: 0.9692\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.9726\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0693 - accuracy: 0.9697\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0690 - accuracy: 0.9721\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0693 - accuracy: 0.9741\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9697\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0601 - accuracy: 0.9795\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0591 - accuracy: 0.9804\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0529 - accuracy: 0.9804\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9790\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0654 - accuracy: 0.9706\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0534 - accuracy: 0.9804\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0515 - accuracy: 0.9814\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0402 - accuracy: 0.9843\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0362 - accuracy: 0.9883\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0353 - accuracy: 0.9887\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9897\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.9799\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0643 - accuracy: 0.9799\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0641 - accuracy: 0.9741\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9868\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9853\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 0.9883\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0382 - accuracy: 0.9853\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9907\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9932\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9932\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9853\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9839\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9883\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9936\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9941\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9912\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9902\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9912\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9902\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9887\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9936\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0278 - accuracy: 0.9936\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9907\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9892\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9902\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9902\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9922\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9927\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9912\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9892\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.9897\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.9927\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9936\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9927\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9951\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9917\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9951\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9966\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9956\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9946\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9922\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9941\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9917\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9956\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9917\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9927\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9941\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9946\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9956\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0119 - accuracy: 0.9971\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9946\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9922\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0275 - accuracy: 0.9892\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9927\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9917\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9936\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9907\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9951\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9951\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9985\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 0.9995\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0063 - accuracy: 0.9976\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9995\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.9956\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 0.9966\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9922\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9966\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9932\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9971\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.9976\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9961\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0131 - accuracy: 0.9951\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.9961\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9936\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9917\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9946\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9936\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9976\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9907\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9897\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9917\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9927\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9932\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9961\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 0.9956\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0232 - accuracy: 0.9946\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9936\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9941\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9936\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9961\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9966\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9980\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0061 - accuracy: 0.9966\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9980\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9980\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9976\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 0.9985\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9976\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9956\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 0.9936\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9883\n",
      "520/520 [==============================] - 2s 3ms/step\n",
      "val_part: 5, test_part: 3, Metric(tp: 581, fp: 1962, tn: 63647, fn: 313, tss: 61.99837093338161)\n",
      "Training [1, 2, 3], Val 5, Test 4\n",
      "length of vals is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foumani/.virtualenvs/solar_flare_prediction/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)       [(None, 60, 24)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)          (None, 60, 128)              24704     ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, 60, 128)              512       ['conv1d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 60, 128)              0         ['batch_normalization_69[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)          (None, 60, 256)              164096    ['activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (None, 60, 256)              1024      ['conv1d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, 60, 256)              0         ['batch_normalization_70[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)          (None, 60, 128)              98432     ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " permute_23 (Permute)        (None, 24, 60)               0         ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (None, 60, 128)              512       ['conv1d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_23 (LSTM)              (None, 8)                    2208      ['permute_23[0][0]']          \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, 60, 128)              0         ['batch_normalization_71[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)        (None, 8)                    0         ['lstm_23[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['activation_71[0][0]']       \n",
      " 3 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenat  (None, 136)                  0         ['dropout_23[0][0]',          \n",
      " e)                                                                  'global_average_pooling1d_23[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 2)                    274       ['concatenate_23[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 291762 (1.11 MB)\n",
      "Trainable params: 290738 (1.11 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 12ms/step - loss: 0.3208 - accuracy: 0.8633\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2007 - accuracy: 0.9210\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 0.9230\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1698 - accuracy: 0.9297\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1506 - accuracy: 0.9422\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1436 - accuracy: 0.9413\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1529 - accuracy: 0.9442\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1398 - accuracy: 0.9437\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1497 - accuracy: 0.9393\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1223 - accuracy: 0.9547\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1282 - accuracy: 0.9494\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1210 - accuracy: 0.9557\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1211 - accuracy: 0.9528\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9538\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1068 - accuracy: 0.9639\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1152 - accuracy: 0.9547\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1008 - accuracy: 0.9591\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9586\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9586\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0976 - accuracy: 0.9629\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 0.9629\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0788 - accuracy: 0.9735\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 0.9701\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0936 - accuracy: 0.9605\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0770 - accuracy: 0.9735\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0793 - accuracy: 0.9721\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0716 - accuracy: 0.9779\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0742 - accuracy: 0.9706\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0719 - accuracy: 0.9706\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9697\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 0.9750\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0726 - accuracy: 0.9721\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0671 - accuracy: 0.9759\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0541 - accuracy: 0.9793\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.9697\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1107 - accuracy: 0.9533\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1036 - accuracy: 0.9634\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1061 - accuracy: 0.9610\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0805 - accuracy: 0.9668\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9803\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9721\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0604 - accuracy: 0.9793\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0461 - accuracy: 0.9841\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9817\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9692\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 0.9841\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0528 - accuracy: 0.9860\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0463 - accuracy: 0.9836\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9865\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9918\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0409 - accuracy: 0.9846\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0330 - accuracy: 0.9880\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0345 - accuracy: 0.9894\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0451 - accuracy: 0.9851\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.9856\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9836\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9812\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0558 - accuracy: 0.9831\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0674 - accuracy: 0.9754\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 0.9904\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9875\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0442 - accuracy: 0.9846\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0424 - accuracy: 0.9846\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9856\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.9831\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9865\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0255 - accuracy: 0.9928\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9889\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9894\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9880\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.9918\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9913\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9942\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9952\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0618 - accuracy: 0.9783\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0455 - accuracy: 0.9856\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9860\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9909\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9942\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0270 - accuracy: 0.9923\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9913\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9913\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9933\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9952\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9899\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 0.9817\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9774\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0711 - accuracy: 0.9735\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0377 - accuracy: 0.9889\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0297 - accuracy: 0.9899\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9928\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9928\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9947\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9942\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9942\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9880\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9909\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9889\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9947\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0278 - accuracy: 0.9889\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9966\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9875\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9851\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0376 - accuracy: 0.9856\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0214 - accuracy: 0.9942\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0122 - accuracy: 0.9947\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9923\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9937\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9976\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9836\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9875\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9952\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0358 - accuracy: 0.9894\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0674 - accuracy: 0.9740\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9831\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9856\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 0.9894\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9918\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9942\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9961\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9957\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 0.9884\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9913\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9957\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9942\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9937\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9952\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 0.9947\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0074 - accuracy: 0.9971\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9961\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9928\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9933\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9947\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9952\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0303 - accuracy: 0.9875\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9909\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9947\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9889\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9909\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0683 - accuracy: 0.9783\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9836\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0415 - accuracy: 0.9851\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9957\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9957\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9947\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9909\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9928\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9947\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9937\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9928\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9947\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0356 - accuracy: 0.9841\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9894\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0405 - accuracy: 0.9851\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9909\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9923\n",
      "520/520 [==============================] - 2s 3ms/step\n",
      "val_part: 5, test_part: 4, Metric(tp: 534, fp: 2106, tn: 63503, fn: 360, tss: 56.521618156618516)\n",
      "method baseline_lstm all evaluations: Metric(tp: 14132, fp: 62545, tn: 1101871, fn: 7972, tss: 58.56276744443238)\n"
     ]
    }
   ],
   "source": [
    "cross_val(context, data, baseline_lstm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T19:00:58.757327400Z",
     "start_time": "2023-08-22T18:45:07.268727900Z"
    }
   },
   "id": "6801faf3a8ac89b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:43:47.843163100Z",
     "start_time": "2023-08-22T18:43:47.826571500Z"
    }
   },
   "id": "e38095d91894f98a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
